



Machine Learning (ML) is a branch of artificial intelligence (AI) that allows computers to learn and make predictions or decisions without being explicitly programmed for each task. Instead, use data to “train” to understand patterns, make predictions, and improve performance over time.

In simpler terms, ML enables computers to automatically improve their performance on a task through experience. Just like humans learn from their experiences, machines learn from the data provided to them.

Types of Machine Learning
There are three main types of machine learning:
1. Supervised Learning
2. Unsupervised Learning
3. Reinforcement Learning

Let’s break down each type and see how they work.

Supervised Learning
In Supervised Learning, the model is trained on labeled data, meaning each input (the data) has a corresponding output (the label). The model learns the relationship between inputs and outputs and can then predict outputs for new, unseen data.

Example:
- Suppose you have a dataset of houses where each house is described by its features (size, number of rooms, location) and a label (price of the house). You can train a supervised learning model to predict the price of a new house based on its features.

Simple Analogy:
Think of a student learning math with a teacher. The teacher (data labels) gives the student (the model) correct answers during practice. Over time, the student learns to solve similar problems on their own.

Unsupervised Learning
In Unsupervised Learning, the data does not have labels. The model is given only the inputs and must find patterns or relationships between them. It often groups similar data points together.

Example:
- Imagine you have a large set of images of different animals, but none of the images are labeled (no “dog,” “cat,” etc.). An unsupervised learning algorithm could group similar images together, forming clusters, even if it doesn’t know what the animals are.

Simple Analogy:
It’s like a person sorting different types of fruits without knowing their names. The person groups similar-looking fruits together (apples in one group, oranges in another) without knowing exactly what they are.

Reinforcement Learning
Reinforcement Learning (RL) involves an agent (a model) that learns through trial and error by interacting with an environment. The agent receives rewards for good actions and penalties for bad actions and adjusts its behavior to maximize rewards over time.

Example:
- In a video game, an RL agent learns to play by making moves and receiving points (rewards) or losing lives (penalties). Over time, it figures out the best strategies to win the game.

Simple Analogy:
Imagine teaching a pet a new trick. Every time the pet performs the trick correctly, you give it a treat (reward). If the pet does something wrong, you don’t give a treat (penalty). Over time, the pet learns to perform the trick correctly to get the treat.

Differences Between Supervised, Unsupervised, and Reinforcement Learning
Press enter or click to view image in full size

Differences Between Supervised, Unsupervised, and Reinforcement Learning
Supervised Learning: Train and Test a Model (Simple Example)
In Supervised Learning, we train a model using a dataset where we already know the correct answers (labels). After training, we evaluate the model’s performance on a separate “test set” to see how well it can predict new data.

Steps:

1. Train the Model: Use a portion of the data (the training set) to teach the model.
2. Test the Model: Use the remaining data (the test set) to evaluate the model’s performance on unseen examples.

Example (Predicting House Prices)

Let’s use a simple example of training and testing a model to predict house prices based on features like size and number of rooms. We will use a supervised learning approach, and sklearn library.

# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Create a simple dataset for house prices
# Features: size (in square feet), number of rooms
# Target: house price in $1000s
data = {
    'size': [1500, 1800, 2400, 3000, 3500, 4000, 4500, 5000, 5500, 6000],
    'rooms': [3, 3, 4, 4, 5, 5, 6, 6, 6, 7],
    'price': [300, 320, 400, 450, 500, 540, 600, 620, 670, 700]
}

# Convert the dictionary to a pandas DataFrame
df = pd.DataFrame(data)

# Define the features (X) and the target (y)
X = df[['size', 'rooms']]  # Input features
y = df['price']  # Target variable

# Split the data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
                                                              random_state=42)

# Train a Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model using Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Output the results
print(f"Predicted prices: {y_pred}")
print(f"Actual prices: {y_test.values}")
print(f"Mean Squared Error: {mse:.2f}")
Why Split Data?
- Training Set: Used to teach the model by showing it examples with known answers.
- Test Set: Used to see how well the model performs on data it has never seen before. This helps check if the model is overfitting (performing well on training but poorly on new data) or generalizing well.

Predictions are made on the test set, and the Mean Squared Error (MSE) is calculated to measure how well the model is performing. The lower the MSE, the better the model’s predictions.

Machine Learning offers powerful tools for making predictions and uncovering insights from data. By understanding the key types (Supervised, Unsupervised, and Reinforcement Learning) and using simple models, you can begin to explore its potential. Supervised learning is often the easiest to start with since you have labeled data, and you can quickly test models with real-world applications like house price prediction or flower classification.

Regression vs. Classification
In machine learning, there are two main types of tasks:

Classification
Regression
1. Classification
Classification involves predicting a category or class label. The output is discrete, meaning the model tries to classify data into predefined labels or groups.

Example:

Predicting whether an email is “spam” or “not spam” (two distinct classes).
Classifying a flower as one of three species based on its features.
2. Regression
Regression involves predicting a continuous value or quantity. The output is continuous, meaning the model predicts a value on a numerical scale.

Example:

Predicting the price of a house based on its features (like size, number of rooms, location).
Forecasting the temperature tomorrow based on historical data.
Understanding Linear Regression
Linear regression is one of the most basic types of regression analysis. It is used to predict a continuous value by modeling the relationship between an independent variable (input) and a dependent variable (output).

Linear Regression Example
Above example of predicting house prices based on the size of the house was an example of linear regression. Linear regression would model this relationship using a straight line:

Press enter or click to view image in full size

Linear Regression
Press enter or click to view image in full size

Linear Regression
We plot the original data and the fitted line to visually see how well the model captures the relationship.

Multivariable (Multiple) Linear Regression
Multiple Linear Regression is an extension of simple linear regression where we use multiple input features (variables) to predict the output.

Instead of just predicting house prices based on size, we could also consider the number of rooms, location, or age of the house. The equation would now look like this:

Press enter or click to view image in full size

Multivariable Regression
Understanding the Cost Function in Machine Learning
A cost function (sometimes called a loss function or error function) is a mathematical function that tells us how far our model’s predictions are from the actual results. It essentially gives a score to a model’s performance: the higher the score, the worse the model; the lower the score, the better the model.

The ultimate goal is to minimize the cost function, which would mean that the model’s predictions are as close to the actual values as possible.

In the case of Gradient Descent, the algorithm adjusts the parameters in such a way that the cost function decreases with each iteration until it reaches a minimum value (the lowest point in the cost function). At this minimum, the model is making the best possible predictions given the training data.

Types of Cost Functions in Machine Learning
1. For Regression (e.g., Linear Regression)*:
The most common cost function for linear regression is the Mean Squared Error (MSE), which looks at the difference between the predicted and actual values, squares them (to avoid negative differences), and averages them over the entire dataset.

Press enter or click to view image in full size

MSE
Where:

n is the number of training examples.
y(i) is the predicted value for the i-th training example.
y(i)^ is the actual value for the i-th training example.

2. For Classification (e.g., Logistic Regression):
The cost function is often the Logarithmic Loss (also known as Cross-Entropy Loss), which measures the error in classifying between categories. For binary classification, this function looks like:
Press enter or click to view image in full size

log loss
Complexity with Multiple Variables (Features)
As we move from simple linear regression (with one feature) to multiple linear regression (with several features), the complexity of the model increases. When we add more features to our dataset, it becomes challenging to compute the optimal values for the parameters (coefficients) using analytical methods like the Gradient descent.

Limitations of Linear Regression
Linear regression, though a very powerful algorithm, has certain disadvantages

Get Rishabh Singh’s stories in your inbox
Join Medium for free to get updates from this writer.

Enter your email
Subscribe
1. Main limitation of Linear Regression is the assumption of linearity between the dependent variable and the independent variables. In the real world, the data is almost never linearly separable. The assumption that there is a straight-line relationship is usually wrong.

2. Prone to noise and overfitting: If the number of observations are lesser than the number of features, Linear Regression should not be used, otherwise it may lead to overfit, and the relationship thus formed will be noisy.

3. Prone to outliers: Linear regression is very sensitive to outliers. An outlier can be considered as an anomaly. It refers to a datapoint which has no clear relationship with any other data point in the data. So, outliers should be analyzed and removed before applying Linear Regression to the dataset, or the linear relationship formed would be highly skewed.


Linear line formed will not correctly predict the results of data points (shown in blue)
Gradient Descent
Gradient Descent is an optimization algorithm used to minimize the cost function by iteratively updating the parameters (coefficients). Gradient Descent iteratively moves toward the optimal solution by following the slope of the cost function.

Press enter or click to view image in full size

Intuition Behind Gradient Descent
Imagine you are standing on a mountain peak and want to reach the lowest point (valley). You can’t see where the valley is because you’re blindfolded. The only thing you can do is feel the ground near you and step in the direction where the slope decreases.

Press enter or click to view image in full size

In this analogy:

The mountain is the cost function.
The goal is to minimize the cost, i.e., find the point with the lowest value (the valley).
Each step you take corresponds to updating the parameters (coefficients) of the model.
How Gradient Descent Works:
Initialize Parameters: Start by assigning random values to the parameters (coefficients).
Compute the Cost Function: The cost function represents the error between the predicted values and actual values. In linear regression, this is often the Mean Squared Error.
Calculate the Gradient (Slope): Compute the slope of the cost function with respect to each parameter. This slope tells us the direction to move the parameters to reduce the cost.
Update Parameters: Adjust the parameters using the gradient and a learning rate (which controls the size of the steps).
Repeat: Continue this process until the parameters converge (when further updates make minimal improvements).
Importance of Learning Rate
The learning rate (α) is a crucial hyperparameter that controls how large each update step is. Learning rate controls how much the coefficients can change on each iteration. If the learning rate is too large, the algorithm might overshoot the minimum and fail to converge. If it’s too small, the algorithm might take too long to find the minimum.

Press enter or click to view image in full size

Learning Rate
Small Learning Rate: Slow convergence, but more precise.
Large Learning Rate: Faster, but risks overshooting and not finding the minimum.

Feature Scaling in Machine Learning
When working with machine learning algorithms, the features (input variables) can often have different scales. For instance, if one feature is measured in kilometers and another in meters, the range of values can differ significantly. Feature scaling helps normalize or standardize these features, ensuring that the model treats them equally during training.

Why Feature Scaling is Important?
Many machine learning algorithms, especially those based on distance or gradient descent, are sensitive to the scale of the input features. Some examples include:

Gradient Descent: The convergence of gradient descent is faster when features are on a similar scale. Without scaling, features with larger ranges dominate the optimization process, making it inefficient.
Types of Feature Scaling
Min-Max Normalization (Rescaling)
Standardization (Z-score scaling)
Let’s explore both techniques with simple examples.

1. Min-Max Normalization
Min-Max normalization scales the data to a fixed range, typically between 0 and 1. Each feature’s minimum value becomes 0, and the maximum value becomes 1.

Press enter or click to view image in full size

Where:

X is the original feature value,
Xmin, Xmax​ are the minimum and maximum values of that feature.
When to Use Min-Max Scaling?
Use Min-Max scaling when you know that the distribution of your data does not contain extreme outliers and is relatively uniform.
It’s commonly used in algorithms like KNN, which are based on distances between data points.
2. Standardization (Z-score Scaling)
Standardization (also called Z-score scaling) transforms the data to have a mean of 0 and a standard deviation of 1. It centers the data by subtracting the mean and then scales by dividing by the standard deviation.


Where:

X is the original feature value,
μ is the mean of the feature,
σ is the standard deviation of the feature.
When to Use Standardization?
Standardization is useful when your data has outliers or when the distribution of features is not uniform.
It’s widely used in algorithms that rely on the Gaussian distribution, such as logistic regression, linear regression, and support vector machines.
When is Feature Scaling Not Necessary?
Not all algorithms are sensitive to the scale of features. For example:

Tree-based models (like Decision Trees, Random Forests) do not require feature scaling since they are based on splitting points in the data and are not sensitive to the relative scales of the features.
Naive Bayes is also insensitive to feature scaling because it relies on probabilities rather than distance or magnitude.
Using Min-Max Scaling with scikit-learn:
from sklearn.preprocessing import MinMaxScaler
import numpy as np

# Original data
data = np.array([[50, 30], [60, 90], [70, 100]])
# Initialize MinMaxScaler
scaler = MinMaxScaler()
# Scale the data
scaled_data = scaler.fit_transform(data)
print("Scaled Data using Min-Max Scaling:
", scaled_data)
Using Standardization with scikit-learn:
from sklearn.preprocessing import StandardScaler
# Initialize StandardScaler
scaler = StandardScaler()
# Scale the data
scaled_data = scaler.fit_transform(data)
print("Scaled Data using Standardization:
", scaled_data)
This is just introduction to ML, we will learn more about ML is detail in future blogs…Stay tuned